2025-02-25 13:40:05,444 - matplotlib.font_manager - INFO - generated new fontManager
2025-02-25 13:40:10,747 - __main__ - INFO - Loaded configuration from config/phase3_config.json
2025-02-25 13:40:10,757 - evaluation.evaluation_framework - INFO - Loaded configuration from C:\Users\Christoph.Hau\Auto eval rag\rag-evaluation-dataset\config\evaluation_config.yaml
2025-02-25 13:40:12,815 - absl - INFO - Using default tokenizer.
2025-02-25 13:40:31,788 - __main__ - WARNING - Connector configuration not found: config/connectors_config.yaml
2025-02-25 13:46:41,491 - __main__ - INFO - Loaded configuration from config/phase3_config.json
2025-02-25 13:46:41,498 - evaluation.evaluation_framework - INFO - Loaded configuration from config/evaluation_config.yaml
2025-02-25 13:46:41,935 - absl - INFO - Using default tokenizer.
2025-02-25 13:46:44,951 - __main__ - INFO - Loaded connector for system: default_rag
2025-02-25 13:46:44,965 - evaluation.evaluation_framework - INFO - Evaluating system: default_rag
2025-02-25 13:46:44,969 - __main__ - ERROR - Error evaluating default_rag: No questions loaded for evaluation
Traceback (most recent call last):
  File "C:\Users\Christoph.Hau\Auto eval rag\rag-evaluation-dataset\scripts\phase3_runner.py", line 285, in _run_evaluation
    results = self.framework.evaluate_system(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Christoph.Hau\Auto eval rag\rag-evaluation-dataset\scripts\evaluation\evaluation_framework.py", line 280, in evaluate_system
    raise ValueError("No questions loaded for evaluation")
ValueError: No questions loaded for evaluation
2025-02-25 13:46:44,972 - evaluation.bias_analyzer - INFO - Loaded 0 questions in total
2025-02-25 13:46:44,972 - evaluation.bias_analyzer - INFO - Loaded results for 0 systems in total
2025-02-25 13:47:41,084 - __main__ - INFO - Loaded configuration from config/phase3_config.json
2025-02-25 13:47:41,084 - evaluation.evaluation_framework - INFO - Loaded configuration from C:\Users\Christoph.Hau\Auto eval rag\rag-evaluation-dataset\config\evaluation_config.yaml
2025-02-25 13:47:41,503 - absl - INFO - Using default tokenizer.
2025-02-25 13:47:44,371 - __main__ - INFO - Loaded connector for system: default_rag
2025-02-25 13:47:44,384 - evaluation.evaluation_framework - INFO - Evaluating system: default_rag
2025-02-25 13:47:44,388 - __main__ - ERROR - Error evaluating default_rag: No questions loaded for evaluation
Traceback (most recent call last):
  File "C:\Users\Christoph.Hau\Auto eval rag\rag-evaluation-dataset\scripts\phase3_runner.py", line 285, in _run_evaluation
    results = self.framework.evaluate_system(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Christoph.Hau\Auto eval rag\rag-evaluation-dataset\scripts\evaluation\evaluation_framework.py", line 280, in evaluate_system
    raise ValueError("No questions loaded for evaluation")
ValueError: No questions loaded for evaluation
2025-02-25 13:47:44,391 - evaluation.bias_analyzer - INFO - Loaded 0 questions in total
2025-02-25 13:47:44,391 - evaluation.bias_analyzer - INFO - Loaded results for 0 systems in total
2025-02-25 13:47:57,402 - __main__ - INFO - Loaded configuration from config/phase3_config.json
2025-02-25 13:47:57,419 - evaluation.evaluation_framework - INFO - Loaded configuration from C:\Users\Christoph.Hau\Auto eval rag\rag-evaluation-dataset\config\evaluation_config.yaml
2025-02-25 13:47:57,820 - absl - INFO - Using default tokenizer.
2025-02-25 13:48:00,745 - __main__ - INFO - Loaded connector for system: default_rag
2025-02-25 13:48:00,766 - evaluation.evaluation_framework - INFO - Evaluating system: default_rag
2025-02-25 13:48:00,770 - __main__ - ERROR - Error evaluating default_rag: No questions loaded for evaluation
Traceback (most recent call last):
  File "C:\Users\Christoph.Hau\Auto eval rag\rag-evaluation-dataset\scripts\phase3_runner.py", line 285, in _run_evaluation
    results = self.framework.evaluate_system(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Christoph.Hau\Auto eval rag\rag-evaluation-dataset\scripts\evaluation\evaluation_framework.py", line 280, in evaluate_system
    raise ValueError("No questions loaded for evaluation")
ValueError: No questions loaded for evaluation
2025-02-25 13:48:00,773 - evaluation.bias_analyzer - INFO - Loaded 0 questions in total
2025-02-25 13:48:00,774 - evaluation.bias_analyzer - INFO - Loaded results for 0 systems in total
2025-02-25 14:07:03,420 - __main__ - INFO - Loaded configuration from config/phase3_config.json
2025-02-25 14:07:03,420 - evaluation.evaluation_framework - INFO - Loaded configuration from C:\Users\Christoph.Hau\Auto eval rag\rag-evaluation-dataset\config\evaluation_config.yaml
2025-02-25 14:07:03,837 - absl - INFO - Using default tokenizer.
2025-02-25 14:07:06,787 - __main__ - INFO - Loaded connector for system: default_rag
2025-02-25 14:07:06,793 - evaluation.evaluation_framework - INFO - Evaluating system: default_rag
2025-02-25 14:07:06,811 - evaluation.evaluation_framework - INFO - Loaded 30 questions for evaluation
2025-02-25 14:07:13,478 - evaluation.evaluation_framework - INFO - Completed question 1/30
2025-02-25 14:07:13,478 - evaluation.evaluation_framework - INFO - Completed question 2/30
2025-02-25 14:07:13,478 - evaluation.evaluation_framework - INFO - Completed question 3/30
2025-02-25 14:07:13,480 - evaluation.evaluation_framework - INFO - Completed question 4/30
2025-02-25 14:07:14,419 - evaluation.evaluation_framework - INFO - Completed question 5/30
2025-02-25 14:07:16,372 - evaluation.evaluation_framework - INFO - Completed question 6/30
2025-02-25 14:07:17,790 - evaluation.evaluation_framework - INFO - Completed question 7/30
2025-02-25 14:07:19,692 - evaluation.evaluation_framework - INFO - Completed question 8/30
2025-02-25 14:07:21,683 - evaluation.evaluation_framework - INFO - Completed question 9/30
2025-02-25 14:07:22,718 - evaluation.evaluation_framework - INFO - Completed question 10/30
2025-02-25 14:07:24,499 - evaluation.evaluation_framework - INFO - Completed question 11/30
2025-02-25 14:07:25,755 - evaluation.evaluation_framework - INFO - Completed question 12/30
2025-02-25 14:07:26,840 - evaluation.rag_system_connector - WARNING - Request failed (attempt 1/3): 500 Server Error: Internal Server Error for url: http://localhost:8000/query
2025-02-25 14:07:34,679 - evaluation.rag_system_connector - WARNING - Request failed (attempt 2/3): 500 Server Error: Internal Server Error for url: http://localhost:8000/query
2025-02-25 14:07:41,114 - evaluation.evaluation_framework - INFO - Completed question 13/30
2025-02-25 14:07:41,114 - evaluation.evaluation_framework - INFO - Completed question 14/30
2025-02-25 14:07:41,114 - evaluation.evaluation_framework - INFO - Completed question 15/30
2025-02-25 14:07:41,114 - evaluation.evaluation_framework - INFO - Completed question 16/30
2025-02-25 14:07:41,114 - evaluation.evaluation_framework - INFO - Completed question 17/30
2025-02-25 14:07:41,114 - evaluation.evaluation_framework - INFO - Completed question 18/30
2025-02-25 14:07:41,114 - evaluation.evaluation_framework - INFO - Completed question 19/30
2025-02-25 14:07:41,114 - evaluation.evaluation_framework - INFO - Completed question 20/30
2025-02-25 14:07:41,114 - evaluation.evaluation_framework - INFO - Completed question 21/30
2025-02-25 14:07:42,234 - evaluation.evaluation_framework - INFO - Completed question 22/30
2025-02-25 14:07:42,857 - evaluation.evaluation_framework - INFO - Completed question 23/30
2025-02-25 14:07:43,653 - evaluation.evaluation_framework - INFO - Completed question 24/30
2025-02-25 14:07:45,596 - evaluation.evaluation_framework - INFO - Completed question 25/30
2025-02-25 14:07:47,017 - evaluation.evaluation_framework - INFO - Completed question 26/30
2025-02-25 14:07:48,666 - evaluation.evaluation_framework - INFO - Completed question 27/30
2025-02-25 14:07:49,586 - evaluation.evaluation_framework - INFO - Completed question 28/30
2025-02-25 14:07:50,639 - evaluation.evaluation_framework - INFO - Completed question 29/30
2025-02-25 14:07:52,630 - evaluation.evaluation_framework - INFO - Completed question 30/30
2025-02-25 14:07:52,631 - evaluation.evaluation_framework - INFO - Calculating evaluation metrics
2025-02-25 14:07:52,638 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,639 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,639 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,639 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,640 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,640 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,640 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,640 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,640 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,640 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,641 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,641 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,641 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,641 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,641 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,641 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,642 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,642 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,642 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,642 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,643 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,643 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,643 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,644 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,644 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,644 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,644 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,644 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,645 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:07:52,645 - evaluation.evaluation_framework - WARNING - Error calculating BLEU score: name 'sentence_bleu' is not defined
2025-02-25 14:09:32,503 - evaluation.evaluation_framework - INFO - Metrics calculation complete
2025-02-25 14:09:32,508 - __main__ - ERROR - Error evaluating default_rag: Object of type RESTAPIConnector is not JSON serializable
Traceback (most recent call last):
  File "C:\Users\Christoph.Hau\Auto eval rag\rag-evaluation-dataset\scripts\phase3_runner.py", line 285, in _run_evaluation
    results = self.framework.evaluate_system(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Christoph.Hau\Auto eval rag\rag-evaluation-dataset\scripts\evaluation\evaluation_framework.py", line 313, in evaluate_system
    json.dump(self.results[evaluation_id], f, indent=2, ensure_ascii=False)
  File "C:\Users\Christoph.Hau\AppData\Local\Programs\Python\Python312\Lib\json\__init__.py", line 179, in dump
    for chunk in iterable:
                 ^^^^^^^^
  File "C:\Users\Christoph.Hau\AppData\Local\Programs\Python\Python312\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "C:\Users\Christoph.Hau\AppData\Local\Programs\Python\Python312\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "C:\Users\Christoph.Hau\AppData\Local\Programs\Python\Python312\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "C:\Users\Christoph.Hau\AppData\Local\Programs\Python\Python312\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "C:\Users\Christoph.Hau\AppData\Local\Programs\Python\Python312\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type RESTAPIConnector is not JSON serializable
2025-02-25 14:09:32,648 - evaluation.bias_analyzer - INFO - Loaded 0 questions in total
2025-02-25 14:09:32,669 - evaluation.bias_analyzer - ERROR - Error loading results from C:\Users\Christoph.Hau\Auto eval rag\rag-evaluation-dataset\evaluation\results\default_rag_results_20250225_140706.json: Expecting value: line 6 column 18 (char 157)
2025-02-25 14:09:32,669 - evaluation.bias_analyzer - INFO - Loaded results for 0 systems in total
2025-02-25 14:09:32,680 - __main__ - ERROR - Error generating reports for default_rag: Expecting value: line 6 column 18 (char 157)
Traceback (most recent call last):
  File "C:\Users\Christoph.Hau\Auto eval rag\rag-evaluation-dataset\scripts\phase3_runner.py", line 390, in _generate_reports
    results = json.load(f)
              ^^^^^^^^^^^^
  File "C:\Users\Christoph.Hau\AppData\Local\Programs\Python\Python312\Lib\json\__init__.py", line 293, in load
    return loads(fp.read(),
           ^^^^^^^^^^^^^^^^
  File "C:\Users\Christoph.Hau\AppData\Local\Programs\Python\Python312\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Christoph.Hau\AppData\Local\Programs\Python\Python312\Lib\json\decoder.py", line 338, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Christoph.Hau\AppData\Local\Programs\Python\Python312\Lib\json\decoder.py", line 356, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 6 column 18 (char 157)
